{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78656cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP FOLIO\\desktop\\llm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the quaint town of Willow Creek, amidst the rolling hills and ancient oak trees, resided a curious girl named Anya. Her life took an unexpected turn when she stumbled upon a peculiar backpack that would forever alter her destiny.\n",
      "\n",
      "The backpack, hidden in an abandoned attic, was a relic of the past. Its leather straps were faded and frayed, and the brass buckle gleamed faintly beneath the cobwebs. Curiosity sparked within Anya as she cautiously lifted it and unzipped the weathered compartment.\n",
      "\n",
      "As the zipper slid open, a soft glow illuminated the backpack's interior. Anya's eyes widened in astonishment as she gazed upon a mesmerizing array of objects. There was a golden quill that wrote effortlessly in any language, a compass that pointed to hidden treasures, and a tiny book that contained the wisdom of ages.\n",
      "\n",
      "With trembling hands, Anya reached into the backpack and retrieved the golden quill. As the tip touched the page of her journal, words flowed effortlessly onto the paper, describing adventures and discoveries yet to come. The compass danced in her palm, its needle spinning and pointing towards a secret waterfall hidden deep within the woods.\n",
      "\n",
      "Emboldened by the backpack's magic, Anya embarked on a series of extraordinary quests. She followed the compass through enchanted forests, where she encountered talking animals and solved ancient riddles. The quill chronicled her every step, capturing her thoughts and dreams in intricate prose.\n",
      "\n",
      "As Anya's reputation as the \"Girl with the Magic Backpack\" spread, curious villagers sought her out to unlock their own hidden potential. With the help of the backpack, she aided a timid musician in finding his voice, a struggling artist in creating masterpieces, and a lost adventurer in charting his course.\n",
      "\n",
      "Through it all, the backpack remained a constant companion, offering wisdom, inspiration, and boundless possibilities. It became a symbol of Anya's boundless curiosity and the transformative power of belief.\n",
      "\n",
      "And so, the tale of Anya and the Magic Backpack was passed down through generations, inspiring countless others to embrace their dreams and unlock the magic within themselves, for in the hands of those who believed, the ordinary became extraordinary.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key='AIzaSyANXKAK_EnJJcYMSSV_G8BkCqyezUPHGz4')\n",
    "\n",
    "llm  = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "prompt = \"Write a story about a magic backpack.\"\n",
    "response = llm .generate_content(prompt)\n",
    "\n",
    "print(response.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6755658c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear [Customer Service Representative Name],\n",
      "\n",
      "I am writing to request a refund for an electronic item I recently purchased from your store.\n",
      "\n",
      "On [date of purchase], I ordered a [product name] with order number [order number]. Upon receiving the product, I encountered the following issues:\n",
      "\n",
      "* [List of issues encountered]\n",
      "\n",
      "These issues have rendered the product unusable for its intended purpose. I have tried troubleshooting the problem myself, but I have been unsuccessful in resolving it.\n",
      "\n",
      "I am very disappointed with the product I received and would like to request a full refund. I have attached a copy of my purchase receipt for your reference.\n",
      "\n",
      "I would appreciate it if you could process my refund as soon as possible. If you have any questions or require further information, please do not hesitate to contact me.\n",
      "\n",
      "Thank you for your prompt attention to this matter.\n",
      "\n",
      "Sincerely,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "response = llm .generate_content(\"write email requesting refund for electronic item\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "704e0828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path='elearning_FAQ.csv', source_column=\"prompt\")\n",
    "\n",
    "# Store the loaded data in the 'data' variable\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46327fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "# Initialize instructor embeddings using the Hugging Face model\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\", cache_folder='E:/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d55fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = instructor_embeddings.embed_query(\"What is your refund policy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134d44a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f4bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a2413f",
   "metadata": {},
   "source": [
    "As you can see above, embedding for a sentance \"What is your refund policy\" is a list of size 768. Looking at the numbers in this list, doesn't give any intuitive understanding of what it is but just assume that these numbers are capturing the meaning of \"What is your refund policy\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e687ecc",
   "metadata": {},
   "source": [
    "### Vector store using FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f149c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Create a FAISS instance for vector database from 'data'\n",
    "vectordb = FAISS.from_documents(documents=data,\n",
    "                                 embedding=instructor_embeddings)\n",
    "\n",
    "# Create a retriever for querying the vector database\n",
    "retriever = vectordb.as_retriever(score_threshold = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014e71dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdocs = retriever.get_relevant_documents(\"how about job placement support?\")\n",
    "rdocs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36096d41",
   "metadata": {},
   "source": [
    "Create RetrievalQA chain along with prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad770bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Given the following context and a question, generate an answer based on this context only.\n",
    "In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
    "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                            chain_type=\"stuff\",\n",
    "                            retriever=retriever,\n",
    "                            input_key=\"query\",\n",
    "                            return_source_documents=True,\n",
    "                            chain_type_kwargs=chain_type_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e428ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain('Do you provide job assistance and also do you provide job gurantee?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8483679b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm)",
   "language": "python",
   "name": "mon_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
